{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python调试LLM_zip_run_hf",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": [
                "--ckpt_dir",
                "/data1/LLM_Models/Meta/llama2/Llama-2-7b-hf",
                "--tokenizer_path",
                "/data1/LLM_Models/Meta/llama2/Llama-2-7b/tokenizer.model",
                "--win_len",
                "4",
                "--text_file",
                "/data2/sp/zip_project/llmzip_v2/test_texts/test.txt",
                "--compression_folder",
                "/data2/sp/zip_project/llmzip_v2/test_texts",
                "--compressed_file_name",
                "/data2/sp/zip_project/llmzip_v2/test_texts/test_4",
                "--compression_alg",
                "ArithmeticCoding",
                "--encode_decode",
                "2",
                "--self_calculate_p",
                "True"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "1",
                "RANK": "0",
                "WORLD_SIZE": "1",
                "LOCAL_RANK": "0",
                "MASTER_ADDR": "127.0.0.1",
                "MASTER_PORT": "29500"
            }
        }
    ]
}